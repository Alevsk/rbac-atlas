---
title: "ollama"
description: "Get up and running with large language models locally."
version: v0.15.0
version_order: f0000f000ff0000
date: ""
service_accounts: 1
workloads: 2
bindings: 0
critical_findings: 0
high_findings: 0
medium_findings: 0
low_findings: 0
categories: [ai, llm, llama, mistral]
tags: [letter-O]
---

## Description

Get up and running with large language models locally.

- https://github.com/ollama/ollama
- https://github.com/otwld/ollama-helm

## Overview

| Identity               | Namespace | Automount | Secrets | Permissions | Workloads | Risk |
| ---------------------- | --------- | --------- | ------- | ----------- | --------- | ---- |
| [`ollama`](#sa-ollama) | default   | âœ…        | â€”       | 0           | 1         | â€”    |

> _Numbers in the last two columns indicate how many bindings or workloads involve each ServiceAccount._

---

## Identities

### ðŸ¤– `ollama` {#sa-ollama}

**Namespace:** `default` Â |Â  **Automount:** âœ…

#### ðŸ”‘ Permissions (0)

_No explicit RBAC bindings._

#### ðŸ“¦ Workloads (1)

| Kind       | Name   | Container | Image                |
| ---------- | ------ | --------- | -------------------- |
| Deployment | ollama | ollama    | ollama/ollama:0.1.25 |

---
