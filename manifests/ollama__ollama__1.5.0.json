{
  "metadata": {
    "version": "1.5.0",
    "name": "ollama",
    "source": "charts/ollama__ollama__1.5.0/",
    "timestamp": 1769794147,
    "extra": {
      "helm": {
        "description": "Get up and running with large language models locally.",
        "home": "https://ollama.ai/",
        "icon": "https://ollama.ai/public/ollama.png",
        "keywords": [
          "ai",
          "llm",
          "llama",
          "mistral"
        ],
        "kubeVersion": "^1.16.0-0",
        "maintainers": [
          {
            "name": "OTWLD",
            "email": "contact@otwld.com"
          }
        ],
        "sources": [
          "https://github.com/ollama/ollama",
          "https://github.com/otwld/ollama-helm"
        ]
      }
    }
  },
  "serviceAccountData": [
    {
      "serviceAccountName": "ollama",
      "namespace": "default",
      "automountToken": true,
      "secrets": null,
      "imagePullSecrets": null
    }
  ],
  "serviceAccountPermissions": [],
  "serviceAccountWorkloads": [
    {
      "serviceAccountName": "",
      "namespace": "default",
      "workloadType": "Pod",
      "workloadName": "ollama-test-connection",
      "containerName": "wget",
      "image": "busybox"
    },
    {
      "serviceAccountName": "ollama",
      "namespace": "default",
      "workloadType": "Deployment",
      "workloadName": "ollama",
      "containerName": "ollama",
      "image": "ollama/ollama:0.5.9"
    }
  ]
}